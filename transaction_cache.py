#!/usr/bin/env python3
"""
E*TRADE Transaction Cache

This module handles fetching and caching of E*TRADE transactions to avoid
repeated API calls and provide efficient access to transaction history.
"""

import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import hashlib
from etrade_simple_api import ETradeSimpleAPI


class TransactionCache:
    def __init__(self, api: ETradeSimpleAPI, cache_dir: str = ".cache"):
        self.api = api
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
    
    def _get_cache_file(self, account_id_key: str) -> str:
        """Generate cache filename for account."""
        # Hash the account key for privacy
        account_hash = hashlib.md5(account_id_key.encode()).hexdigest()[:8]
        return os.path.join(self.cache_dir, f"transactions_{account_hash}.json")
    
    def _load_cache(self, account_id_key: str) -> Dict[str, Any]:
        """Load cached transactions for account."""
        cache_file = self._get_cache_file(account_id_key)
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r') as f:
                    cache_data = json.load(f)
                    # Convert date strings back to timestamps for consistency
                    return cache_data
            except (json.JSONDecodeError, FileNotFoundError):
                print("âš ï¸  Cache file corrupted, will rebuild")
                return {'transactions': [], 'last_updated': None}
        return {'transactions': [], 'last_updated': None}
    
    def _save_cache(self, account_id_key: str, transactions: List[Dict[str, Any]]) -> None:
        """Save transactions to cache."""
        cache_file = self._get_cache_file(account_id_key)
        cache_data = {
            'transactions': transactions,
            'last_updated': datetime.now().isoformat()
        }
        try:
            with open(cache_file, 'w') as f:
                json.dump(cache_data, f, indent=2)
        except Exception as e:
            print(f"âš ï¸  Failed to save cache: {e}")
    
    def _fetch_recent_transactions(self, account_id_key: str, count: int = 50) -> List[Dict[str, Any]]:
        """Fetch recent transactions from API."""
        try:
            response = self.api.get_account_transactions(account_id_key, count=count)
            
            if 'Transaction' not in response:
                if isinstance(response, dict) and 'code' in response:
                    print(f"âŒ API Error: {response.get('message', 'Unknown error')}")
                return []
            
            transactions = response['Transaction']
            if not isinstance(transactions, list):
                transactions = [transactions]
            
            return transactions
        except Exception as e:
            print(f"âŒ Error fetching transactions: {e}")
            return []
    
    def _fetch_paginated_transactions(self, account_id_key: str, days_back: int = 30) -> List[Dict[str, Any]]:
        """Fetch transactions using pagination to get full history."""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)

        all_transactions = []
        seen_ids = set()  # Track transaction IDs to prevent duplicates
        marker = None
        max_calls = 20
        call_count = 0
        oldest_date_found = None

        print(f"ðŸ“Š Fetching full transaction history for {days_back} days...")

        while call_count < max_calls:
            call_count += 1
            print(f"ðŸ”„ API call {call_count}/{max_calls}...")

            try:
                response = self.api.get_account_transactions(account_id_key, count=50, marker=marker)

                if 'Transaction' not in response:
                    print(f"âš ï¸  No more transactions found (call {call_count})")
                    break

                transactions = response['Transaction']
                if not isinstance(transactions, list):
                    transactions = [transactions]

                # Track oldest date and add transactions (with deduplication)
                new_transactions = []
                new_unique_count = 0
                for trans in transactions:
                    trans_id = trans.get('transactionId')

                    # Skip if we've already seen this transaction
                    if trans_id in seen_ids:
                        continue

                    seen_ids.add(trans_id)
                    new_unique_count += 1

                    try:
                        trans_date_ms = int(trans.get('transactionDate', 0))
                        trans_date_obj = datetime.fromtimestamp(trans_date_ms / 1000)

                        if oldest_date_found is None or trans_date_obj < oldest_date_found:
                            oldest_date_found = trans_date_obj

                        # Only include transactions within date range
                        if start_date <= trans_date_obj <= end_date:
                            new_transactions.append(trans)
                    except (ValueError, TypeError):
                        continue

                all_transactions.extend(new_transactions)
                print(f"  âœ… Found {len(new_transactions)} transactions in range ({new_unique_count} new, {len(transactions) - new_unique_count} duplicates, total: {len(all_transactions)})")

                # If we didn't get any new unique transactions, we're done
                if new_unique_count == 0:
                    print("ðŸ“„ No new transactions found - pagination complete")
                    break

                # Check stopping conditions
                if oldest_date_found and oldest_date_found < start_date:
                    print(f"ðŸ“… Found transactions older than {start_date.strftime('%m/%d/%Y')}")
                    break

                # Check if we've fetched all available transactions
                total_count = response.get('totalCount', 0)
                if total_count and len(seen_ids) >= int(total_count):
                    print(f"ðŸ“„ Fetched all {total_count} available transactions")
                    break

                # Also check moreTransactions flag (though totalCount is more reliable)
                more_transactions = response.get('moreTransactions', 'false')
                has_more = str(more_transactions).lower() == 'true'

                if not has_more and not total_count:
                    # Only stop if both indicators say we're done
                    print("ðŸ“„ API reports no more transactions available")
                    break

                # Use the API's marker field if available, otherwise fall back to transaction ID
                if 'marker' in response:
                    marker = response['marker']
                    print(f"  ðŸ“ Using API marker: {marker}")
                elif transactions:
                    marker = transactions[-1].get('transactionId')
                    if not marker:
                        print("âš ï¸  No marker or transaction ID for pagination")
                        break
                else:
                    print("âš ï¸  No transactions or marker to continue pagination")
                    break

            except Exception as e:
                print(f"âŒ Error in pagination call {call_count}: {e}")
                break

        print(f"âœ… Fetched {len(all_transactions)} unique transactions from {call_count} API calls")
        return all_transactions
    
    def get_transactions(self, account_id_key: str, days_back: int = 7, force_refresh: bool = False) -> List[Dict[str, Any]]:
        """
        Get transactions with intelligent caching.
        
        Args:
            account_id_key: Account identifier
            days_back: Number of days to fetch
            force_refresh: Force refresh from API
        
        Returns:
            List of transaction dictionaries
        """
        if force_refresh:
            print("ðŸ”„ Force refresh requested, fetching from API...")
            transactions = self._fetch_paginated_transactions(account_id_key, days_back)
            self._save_cache(account_id_key, transactions)
            return transactions
        
        # Load cache
        cache_data = self._load_cache(account_id_key)
        cached_transactions = cache_data.get('transactions', [])
        
        if not cached_transactions:
            print("ðŸ“ No cached transactions, fetching full history...")
            transactions = self._fetch_paginated_transactions(account_id_key, days_back)
            self._save_cache(account_id_key, transactions)
            return transactions
        
        # Check if we need fresh data by fetching recent transactions
        print("ðŸ” Checking for new transactions...")
        recent_transactions = self._fetch_recent_transactions(account_id_key, 50)
        
        if not recent_transactions:
            print("âš ï¸  No recent transactions found, using cache")
            return self._filter_by_date_range(cached_transactions, days_back)
        
        # Check if any recent transactions are new (not in cache)
        cached_ids = {t.get('transactionId') for t in cached_transactions}
        new_transactions = [t for t in recent_transactions if t.get('transactionId') not in cached_ids]
        
        if new_transactions:
            print(f"âœ¨ Found {len(new_transactions)} new transactions, updating cache...")
            # Merge new transactions with cache and sort by date (newest first)
            all_transactions = new_transactions + cached_transactions
            all_transactions = self._sort_transactions(all_transactions)
            # Remove duplicates (shouldn't happen, but just in case)
            all_transactions = self._deduplicate_transactions(all_transactions)
            self._save_cache(account_id_key, all_transactions)
            return self._filter_by_date_range(all_transactions, days_back)
        else:
            print("âœ… Cache is up to date")
            return self._filter_by_date_range(cached_transactions, days_back)
    
    def _filter_by_date_range(self, transactions: List[Dict[str, Any]], days_back: int) -> List[Dict[str, Any]]:
        """Filter transactions to specified date range."""
        end_date = datetime.now()
        # Use start of day for start_date to include all transactions on that day
        start_date = (end_date - timedelta(days=days_back)).replace(hour=0, minute=0, second=0, microsecond=0)

        filtered = []
        for trans in transactions:
            try:
                trans_date_ms = int(trans.get('transactionDate', 0))
                trans_date_obj = datetime.fromtimestamp(trans_date_ms / 1000)
                if start_date <= trans_date_obj <= end_date:
                    filtered.append(trans)
            except (ValueError, TypeError):
                continue

        return filtered
    
    def _sort_transactions(self, transactions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Sort transactions by date (newest first)."""
        def get_date(trans):
            try:
                return int(trans.get('transactionDate', 0))
            except (ValueError, TypeError):
                return 0
        
        return sorted(transactions, key=get_date, reverse=True)
    
    def _deduplicate_transactions(self, transactions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Remove duplicate transactions based on transaction ID."""
        seen_ids = set()
        deduplicated = []
        
        for trans in transactions:
            trans_id = trans.get('transactionId')
            if trans_id and trans_id not in seen_ids:
                seen_ids.add(trans_id)
                deduplicated.append(trans)
        
        return deduplicated
    
    def get_transaction_summary(self, account_id_key: str, days_back: int = 7) -> Dict[str, Any]:
        """Get summary statistics for transactions."""
        transactions = self.get_transactions(account_id_key, days_back)
        
        if not transactions:
            return {
                'total_transactions': 0,
                'date_range': 'No transactions',
                'transaction_types': {},
                'oldest_date': None,
                'newest_date': None
            }
        
        # Analyze transactions
        transaction_types = {}
        dates = []
        
        for trans in transactions:
            trans_type = trans.get('transactionType', 'Unknown')
            transaction_types[trans_type] = transaction_types.get(trans_type, 0) + 1
            
            try:
                trans_date_ms = int(trans.get('transactionDate', 0))
                trans_date_obj = datetime.fromtimestamp(trans_date_ms / 1000)
                dates.append(trans_date_obj)
            except (ValueError, TypeError):
                continue
        
        dates.sort()
        
        return {
            'total_transactions': len(transactions),
            'date_range': f"{dates[0].strftime('%m/%d/%Y')} - {dates[-1].strftime('%m/%d/%Y')}" if dates else 'No valid dates',
            'transaction_types': transaction_types,
            'oldest_date': dates[0] if dates else None,
            'newest_date': dates[-1] if dates else None
        }
    
    def clear_cache(self, account_id_key: Optional[str] = None) -> None:
        """Clear cache for specific account or all accounts."""
        if account_id_key:
            cache_file = self._get_cache_file(account_id_key)
            if os.path.exists(cache_file):
                os.remove(cache_file)
                print(f"âœ… Cleared cache for account")
        else:
            # Clear all cache files
            for filename in os.listdir(self.cache_dir):
                if filename.startswith('transactions_') and filename.endswith('.json'):
                    os.remove(os.path.join(self.cache_dir, filename))
            print("âœ… Cleared all transaction caches")